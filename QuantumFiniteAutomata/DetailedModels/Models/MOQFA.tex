\subsection{\glsentrylong{mo-1qfa}}
\label{sec:moqfa}

\subsubsection{Introduction}
\glspl{mo-1qfa} represent one of the simplest models of quantum computation in the realm of automata theory. Introduced by Moore and Crutchfield in 2000~\cite{moore2000quantum}, \glspl{mo-1qfa} evolve solely through unitary transformations corresponding to the input symbols and perform a single measurement at the end of the computation. This model has been further characterized by Brodsky and Pippenger~\cite{brodsky2002characterizations}, and it is known for its conceptual simplicity as well as for its limitations. Notably, when restricted to bounded error, \glspl{mo-1qfa} recognize exactly the class of group languages—a proper subset of the regular languages. In contrast, the measure-many variant ~\cite{kondacs1997power} employs intermediate measurements and exhibits different acceptance capabilities.

\subsubsection{Formal Definition}
An \gls{mo-1qfa} is formally defined as a 5-tuple 
\[
M = (Q,\Sigma,\delta,q_0,F),
\]
where:
\begin{itemize}
    \item $Q$ is a finite set of states,
    \item $\Sigma$ is a finite input alphabet, typically augmented with a designated end-marker (e.g., \$),
    \item $\delta : Q \times \Sigma \times Q \to \mathbb{C}$ is the transition function such that, for every symbol $\sigma\in\Sigma$, the matrix 
    \[
    U_\sigma,\quad \text{with} \quad (U_\sigma)_{q,q'} = \delta(q,\sigma,q'),
    \]
    is unitary~\cite{moore2000quantum},
    \item $q_0 \in Q$ is the initial state, and
    \item $F\subseteq Q$ is the set of accepting states.
\end{itemize}
For an input string $x=x_1x_2\cdots x_n$, the computation proceeds by applying the corresponding unitary matrices sequentially:
\[
|\Psi_x\rangle = U_{x_n}U_{x_{n-1}}\cdots U_{x_1}|q_0\rangle.
\]
After reading the entire input, a measurement is performed using the projection operator
\[
P=\sum_{q\in F} |q\rangle\langle q|,
\]
so that the acceptance probability is defined as
\[
p_M(x)=\|P\,|\Psi_x\rangle\|^2.
\]
Alternative characterizations, including formulations using the Heisenberg picture, have been discussed in~\cite{qiu2004characterizations,piazza2022mirrors}.

\subsubsection{Strings Acceptance}
A string $x$ is accepted by an \gls{mo-1qfa} if the acceptance probability $p_M(x)$ exceeds a predetermined cut-point $\lambda$. In a bounded error setting, there exists a margin $\epsilon > 0$ such that:
\[
\forall x\in L:\quad p_M(x) \ge \lambda + \epsilon,
\]
\[
\forall x\notin L:\quad p_M(x) \le \lambda - \epsilon.
\]
Under the unbounded error regime, \glspl{mo-1qfa} can accept some nonregular languages (for instance, solving the word problem over the free group)~\cite{brodsky2002characterizations}. The precise acceptance behavior thus depends on whether a cut-point or a bounded error framework is adopted.

\subsubsection{Set of Languages Accepted}
When \glspl{mo-1qfa} are restricted to bounded error acceptance, they recognize exactly the class of \emph{group languages}—languages whose syntactic semigroups form groups~\cite{brodsky2002characterizations}. This class forms a strict subset of the regular languages, emphasizing the inherent limitation of the \gls{mo-1qfa} model. In contrast, by relaxing the error bounds, one may design \glspl{mo-1qfa} that accept a broader range of languages, albeit often at the cost of increased computational complexity.

\subsubsection{Closure Properties}
The class of languages accepted by \glspl{mo-1qfa} under bounded error exhibits robust closure properties. Specifically, this class is closed under:
\begin{itemize}
    \item Inverse Homomorphisms~\cite{brodsky2002characterizations},
    \item Word Quotients~\cite{brodsky2002characterizations},
    \item Boolean Operations (union, intersection, and complement)~\cite{freivalds2005languages,bertoni2003quantum}.
\end{itemize}
Additional algebraic properties, including aspects related to the pumping lemma and the structure of the accepting probabilities, have been further elaborated in works such as Ambainis et al.~\cite{ambainis1999probabilities} and Xi et al.~\cite{xi2008some}.

\subsubsection{Summary of Advantages and Limitations}
\glspl{mo-1qfa} are praised for their simplicity. Since the quantum state evolves unitarily until a single measurement is made, the model avoids the complications associated with intermediate state collapses. This simplicity has practical implications; for example, recent experimental work has shown that custom control pulses can significantly reduce error rates in IBM-Q implementations~\cite{lussi2024implementing}, and photonic implementations have further demonstrated the feasibility of \glspl{mo-1qfa} in optical setups~\cite{candeloro2021enhanced}. On the downside, the acceptance power of \glspl{mo-1qfa} is limited—when operating under bounded error, they recognize only the group languages, which form a strict subset of the regular languages. In contrast, \glspl{mm-1qfa} offer greater acceptance power but at the cost of increased model complexity~\cite{kondacs1997power,berzicna2001ambainis}.

\subsubsection{Example}
Consider a simple \gls{mo-1qfa} defined over the unary alphabet $\Sigma=\{a\}$ with state set $Q=\{q_0,q_1\}$, initial state $q_0$, and accepting state set $F=\{q_1\}$. Let the unitary operator corresponding to the symbol $a$ be defined by the rotation matrix:
\[
U_a = \begin{pmatrix}
\cos\theta & -\sin\theta \\
\sin\theta & \cos\theta
\end{pmatrix},
\]
for a fixed angle $\theta$. For an input string $a^n$, the state evolves as:
\[
|\Psi_{a^n}\rangle = U_a^n |q_0\rangle.
\]
The acceptance probability is computed as:
\[
p_M(a^n)=\|P\,|\Psi_{a^n}\rangle\|^2,
\]
where the projection operator $P$ is given by $P=|q_1\rangle\langle q_1|$. By appropriately choosing $\theta$, the automaton can be tuned so that $p_M(a^n)$ exceeds the cut-point $\lambda$ (for example, $\lambda=\frac{1}{2}$) if and only if $a^n$ belongs to the target language. This example illustrates the essential mechanism of \glspl{mo-1qfa}, as described in~\cite{moore2000quantum,brodsky2002characterizations}.

\subsubsection{Additional Topics}
\paragraph{Learning and Optimization:} Recent work by Chu et al.~\cite{chu2023approximately} has introduced methods that combine active learning with non-linear optimization to approximately learn the parameters of \glspl{mo-1qfa}. These techniques provide insights into how one can recover the unitary transformations and state structure from observed data.

\paragraph{Complexity and Minimization:} The problem of minimizing the number of states in an \gls{mo-1qfa} was originally posed by Moore and Crutchfield~\cite{moore2000quantum}. Subsequent work by Mateus, Qiu, and Li~\cite{mateus2012complexity} has established an EXPSPACE upper bound for the minimization problem, framing it as a challenge in solving systems of algebraic polynomial (in)equations.

\paragraph{Experimental Implementations:} Experimental realizations of \glspl{mo-1qfa} have also been explored. Lussi et al.~\cite{lussi2024implementing} demonstrated an implementation on IBM-Q devices using custom control pulses, while photonic approaches have been reported in~\cite{candeloro2021enhanced}. These works highlight both the practical challenges and the potential advantages of implementing \glspl{mo-1qfa} on current quantum hardware.

\paragraph{Future Directions:} Future research may focus on further enhancing experimental implementations, developing more robust learning algorithms for \glspl{mo-1qfa}, and exploring new minimization techniques that could lead to more efficient automata. Extensions that combine features of \glspl{mo-1qfa} and \gls{mm-1qfa}s may also provide richer language recognition capabilities and deepen our understanding of quantum computational models.

