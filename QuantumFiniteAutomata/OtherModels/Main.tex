\section{Other Models of Quantum Finite Automata}
\label{sec:other-models}

Beyond the core models of quantum finite automata discussed in the previous sections, the literature also presents several alternative models that explore different computational paradigms, theoretical extensions, or enhancements. While these models are less prominent or less widely used, they offer valuable insights into the boundaries and variations of quantum automata theory.

In this section, we provide a concise overview of some notable variants. Each model is briefly introduced with its main characteristics and distinguishing features, along with references to the original works in which they were proposed. Readers interested in further details are encouraged to consult the cited articles.

\subsection{Quantum Turing Machines} 
The \gls{qtm} is the quantum analog of a classical Turing machine, featuring an infinite tape and a moving head with quantum states and unitary transitions. It was first proposed by Deutsch in 1985 as a general model of quantum computation \cite{deutsch1985quantum}. A QTM can implement any quantum algorithm and is computationally equivalent to the quantum circuit model (Yao proved that any QTM can be efficiently simulated by quantum circuits and vice versa \cite{yao1993quantum}). Unlike finite automata models, the QTM is not limited to \glspl{reg} - it has unbounded memory and can recognize non-\glspl{reg} - but this generality comes at the cost of a much more complex machine description. In practice, QTMs serve mostly as a theoretical cornerstone since simpler models (like quantum circuits) are used for designing algorithms, yet the QTM remains important for defining quantum complexity classes and formalizing the Church-Turing principle in the quantum realm.

\subsection{Latvian Quantum Finite Automata} 
The term \gls{lqfa} refers to the one-way quantum finite automaton model introduced by Ambainis and Freivalds (who are Latvian) in 1998 \cite{ambainis19981}. This model is essentially the \emph{measure-once} 1QFA: the machine's state evolves unitarily as it reads the input, and only after reaching the end of the input is a single projective measurement performed to decide acceptance. (In contrast, the earlier \gls{qfa} model by Kondacs and Watrous allowed measurements after each step.) The Latvian 1QFA demonstrated that even with a single end-of-input measurement, a quantum automaton can recognize certain \glspl{reg} with exponentially fewer states than any equivalent deterministic automaton. However, like other 1QFAs, it cannot recognize all \glspl{reg}. The LQFA is historically significant as one of the first quantum automata models, and its state-efficiency advantages and limitations were studied in subsequent works.

\subsection{\texorpdfstring{$l$}{l}-valued Finite Automata} 
An \gls{l-vfa} is an automaton model based on multi-valued logic (in particular, on quantum logic), rather than probabilistic or binary state transitions. This model was explored by Ying (2000) and was later formalized and extended by Qiu in 2007 as a “logical” approach to quantum computation \cite{qiu2007automata}. In an l-VFA, the transition function is not strictly deterministic or probabilistic - instead, each transition from a state $p$ to a state $q$ on an input symbol $\sigma$ is assigned a truth-value from a complete orthomodular lattice $L$. Intuitively, $\delta(p,\sigma,q)$ may be 0, 1, or some intermediate truth-value in $L$. A string is accepted by an l-VFA if the aggregated truth-value of all paths leading to an accepting state evaluates to 1 in the lattice sense. This construction generalizes classical finite automata and provides a way to apply quantum logic to automata theory.

\subsection{\texorpdfstring{$l$}{l}-valued Pushdown Automata} 
The \gls{l-vpda} extends the idea of an l-VFA by adding a pushdown stack, thus enabling recognition of some non-\glspl{reg} within the $l$-valued logic framework. This model was introduced alongside l-VFAs by Qiu in 2007 \cite{qiu2007automata} as part of the effort to build automata theory on quantum logic. An l-VPDA operates similarly to a classical pushdown automaton, but its state transitions and stack operations carry truth-values in a lattice $L$ instead of deterministic outcomes.

\subsection{Quantum Automata with Advice} 
\glsentrylong{qfa-adv} are variants of 1QFA that are supplemented with an additional input - an advice string or quantum state - that depends only on the input length $n$ and is provided to the automaton to improve its computation. This idea was studied by Yamakami (2014) \cite{yamakami2014one}. In his model, the machine can utilize a pre-prepared quantum advice state during its computation, allowing for potentially improved computational power while still remaining weaker than full quantum Turing machines.

\subsection{Enhanced Quantum Finite Automata} 
\gls{e-1qfa} is a variant of the one-way QFA where the machine's state can be measured after each symbol is read, rather than restricting measurement to occur only at the end of the input. This model was introduced by Nayak \cite{nayak1999optimal} and studied further by Lin \cite{lin2012another}. It allows the computation to dynamically adapt based on partial measurement outcomes, making it slightly more powerful than traditional one-way QFAs in certain contexts.

\subsection{Postselection Quantum Finite Automata} 
\gls{pqfa} is a theoretical model that augments a quantum finite automaton with the power of \emph{postselection} - the ability to conditionally proceed based on a desired measurement outcome. This powerful but unphysical feature was used to explore computational limits, and the model was studied in depth by Scegulnaja-Dubrovska et al. \cite{scegulnaja2010postselection} and originally proposed in the context of quantum complexity by Aaronson \cite{aaronson2005quantum}.

\subsection{\texorpdfstring{$\omega$}{omega} Quantum Finite Automata}
\gls{omega-qfa} extend quantum finite automata to operate on infinite input strings. Bhatia and Kumar (2019) introduced several formal models with different acceptance conditions like Büchi, Rabin, and Streett \cite{bhatia2019quantum}. These models are important for exploring quantum computation over streams or continuous inputs and show intriguing differences from their classical counterparts.

\subsection{Promise Problems and Quantum Finite Automata}

Promise problems are a generalization of language recognition where an automaton is required to correctly classify inputs from two disjoint sets: the “yes” instances and the “no” instances. This relaxed setting provides a useful framework for analyzing subtle distinctions in computational power, especially when comparing classical and quantum models.

\gls{qfa} have demonstrated significant advantages in the context of promise problems. These models are often more state-efficient or capable of solving problems that classical automata cannot handle with bounded error. One notable study by Zheng et al.\ \cite{zheng2013state} investigates the \gls{2qcfa} model and demonstrates its exponential state succinctness over classical counterparts for families of promise problems. For example, they construct a 2QCFA that solves a problem with constant quantum memory and logarithmic classical memory, whereas equivalent classical automata require exponentially more states.

Other works explore theoretical implications of quantum advantages under promises. Rashid and Yakaryilmaz \cite{rashid2014implications} analyze how quantum automata solving promise problems can relate to foundational concepts like contextuality in quantum theory. Bianchi et al.\ \cite{bianchi2014complexity} examine the computational complexity of promise problems across classical and quantum finite automata, identifying specific contexts where quantum models are strictly more efficient. Gruska et al.\ \cite{gruska2015potential} further study promise problems under exact acceptance and show that \gls{qfa} can solve certain structured promise problems with significantly fewer states than their classical counterparts.

Overall, the study of promise problems has emerged as a rich area to highlight the computational advantages of quantum models, often revealing separations that are not observable in standard language recognition settings.
