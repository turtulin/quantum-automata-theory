\subsection{\glsentrylong{mmqfa}}
\label{sec:mmqfa}
This section introduces measure-many quantum finite automata (MM-QFAs), a model in which a measurement is performed after every transition. In MM-QFAs, the state space is partitioned into accepting, rejecting, and nonhalting subspaces, allowing the automaton to potentially halt before reading the entire input.

\subsubsection{Definition}
An MM-QFA is defined as a 6-tuple
\[
M = (Q, \Sigma, \delta, q_0, Q_{\text{acc}}, Q_{\text{rej}}),
\]
where:
\begin{itemize}
  \item $Q$ is a finite set of states.
  \item $\Sigma$ is a finite input alphabet; an end-marker (e.g., $\$$) is appended to the input.
  \item $\delta$ is a unitary transition function that maps transitions between states for each input symbol.
  \item $q_0\in Q$ is the initial state.
  \item $Q_{\text{acc}}\subset Q$ is the set of halting accepting states.
  \item $Q_{\text{rej}}\subset Q$ is the set of halting rejecting states, with $Q_{\text{acc}}\cap Q_{\text{rej}}=\emptyset$. The remaining states, denoted by $Q_{\text{non}} = Q \setminus (Q_{\text{acc}}\cup Q_{\text{rej}})$, are nonhalting.
\end{itemize}
After reading each input symbol, the automaton applies the corresponding unitary transformation and then performs a measurement that projects the current state into one of the three subspaces (nonhalting, accepting, or rejecting). The process continues until the end-marker is reached or the automaton halts.

\subsubsection{Accepted Strings}
For an input string $x\in\Sigma^*$, the computation begins in the state $q_0$. As each symbol is read, the automaton evolves unitarily and a measurement is performed immediately. The cumulative probability of acceptance is obtained by summing the probabilities that the system collapses into an accepting state over all measurement steps. A string is accepted if this overall acceptance probability exceeds the designated cut-point (or lies above a margin in the bounded error model).

\subsubsection{Language Acceptance}
An MM-QFA accepts a language $L\subseteq\Sigma^*$ if there exists a cut-point $\lambda$ such that for every $x\in L$ the acceptance probability satisfies
\[
p_M(x) > \lambda,
\]
and for every $x\notin L$, it holds that
\[
p_M(x) \le \lambda.
\]
In the bounded error setting, there is an $\epsilon > 0$ such that for all $x\in L$, $p_M(x)\ge \lambda + \epsilon$, and for all $x\notin L$, $p_M(x)\le \lambda - \epsilon$. The class of languages recognized by MM-QFAs under bounded error is known to have distinct closure and decidability properties.

\subsubsection{Properties}
MM-QFAs exhibit several notable properties:
\begin{itemize}
  \item \textbf{Closure Properties:} The classes of languages accepted by MM-QFAs (both in the bounded and unbounded error cases) are closed under complement, inverse homomorphisms, and word quotients. However, they are not closed under arbitrary homomorphisms.
  \item \textbf{Decidability:} The equivalence problem—deciding whether two MM-QFAs yield the same acceptance probabilities for all inputs—is decidable using bilinearization and related algorithmic techniques.
  \item \textbf{Computational Power:} Although MM-QFAs can recognize some languages that are beyond the power of measure-once QFAs, when restricted to bounded error, they still accept only a proper subset of the regular languages.
\end{itemize}

\subsubsection{Description}
The main features of MM-QFAs include:
\begin{itemize}
  \item \textbf{Intermediate Measurements:} By performing a measurement after every transition, MM-QFAs update their cumulative acceptance and rejection probabilities as the input is processed. This allows the automaton to halt early if a conclusive result is reached.
  \item \textbf{State Partitioning:} The state set is divided into three disjoint subspaces—nonhalting, accepting, and rejecting—which guides the computation and determines the final outcome.
  \item \textbf{Enhanced Flexibility:} The frequent measurements provide additional control over the computation, enabling MM-QFAs to simulate some behaviors of classical reversible automata and, in certain cases, to require fewer states than equivalent classical models.
  \item \textbf{Trade-Offs:} While intermediate measurements can enhance decision power, they also collapse quantum superpositions, thereby limiting the ability to exploit interference over long computation paths.
\end{itemize}

\subsubsection{Comparison with Other Models}
MM-QFAs differ from other quantum finite automata models in several respects:
\begin{itemize}
  \item \textbf{Versus MO-QFAs:} Unlike measure-once QFAs, which perform a single measurement at the end of the computation, MM-QFAs measure after every transition. This can enable early termination and more dynamic error management, though it also restricts the use of quantum interference.
  \item \textbf{Versus Classical Models:} While classical deterministic and probabilistic finite automata process symbols without the notion of quantum superposition, MM-QFAs leverage unitary evolution and measurement-induced collapse, blending classical probabilistic behavior with quantum effects.
  \item \textbf{Versus Two-Way QFAs:} Compared to two-way QFAs that allow bidirectional movement of the tape head, MM-QFAs typically process the input in one direction, trading off head mobility for a more streamlined measurement process.
\end{itemize}

\subsubsection{Examples}
An illustrative example of an MM-QFA is one designed to recognize the language 
\[
L = \{x \in \{a,b\}^* \mid x \text{ ends with } b\}.
\]
In this example, the automaton is constructed with a small number of states. As the input is read symbol by symbol, a unitary transition is applied followed by a measurement. If the last symbol read is $b$, the measurement is likely to project the automaton into an accepting state; if it is $a$, the probability of transitioning to a rejecting state increases. This example demonstrates how the repeated measurements in an MM-QFA can guide the computation toward an early and correct decision based on the input.
