%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Comparative Analysis of Quantum Finite Automata Models
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Comparative Analysis of Quantum Finite Automata Models}
\label{chap:comparative-analysis}
This chapter provides a comprehensive comparison of \gls{qfa} models, structured into nine categories. Key evaluation criteria include state complexity, error handling, and implementation feasibility. 
The models are organized to reflect the structure of the chapter~\ref{chap:literature-review}, with each category representing a distinct class of QFA models.
For each category, we summarize the operational mechanisms, present visual comparisons, and underline the most relevant models and their trade-offs. We then compare these groups across each other and conclude with an overall evaluation highlighting the most and least promising approaches.

\section{Models Comparison}
This section provides a detailed comparative analysis across the models presented in chapter~\ref{chap:literature-review}. We group the models into nine categories based on their operational mechanisms and complexity. For each category, we summarise the main characteristics, highlighting the main differences and trade-offs. We then compare the models across categories to identify the most promising approaches for practical quantum computing applications.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection*{\glsentrylongpl{1qfa}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Summary}
One-way QFAs process input left-to-right with varying measurement strategies:
\begin{itemize}
    \item \textbf{\gls{mo-1qfa}}: Implements unitary evolution with a single final measurement. Recognizes reversible regular languages with zero error. State complexity is typically $O(\log n)$, but the model is non-closed under union.
    \item \textbf{\gls{mm-1qfa}}: Uses intermediate measurements, enabling bounded-error recognition of all regular languages. It has an exponential state advantage over PFAs but suffers from measurement overhead.
    \item \textbf{\gls{lqfa}}: Uses immediate post-symbol measurements to balance quantum coherence and decision making, particularly for parity languages.
    \item \textbf{\gls{1qfac}/\gls{cl-1qfa}}: Hybrid models that combine classical state control with quantum updates, achieving efficient DFA simulation with constant quantum memory. However, equivalence checking is undecidable \cite{hirvensalo2008}.
    \item \textbf{\gls{a-qfa}/\gls{mlqfa}}: Enhanced models that use ancillary \glspl{qubit} (\gls{a-qfa}) or multi-letter block processing (\gls{mlqfa}) to recognize \glsentrylongpl{csl}. \glspl{mlqfa}, however, suffer from exponential state growth in the block size $k$ \cite{ravikumar2003}.
\end{itemize}

\subsubsection{Comparison}
\begin{figure}[ht]
\centering
\begin{tikzpicture}[node distance=2.5cm, auto]
    \node[draw,rectangle,fill=blue!15,minimum width=2cm] (mo) {\gls{mo-1qfa}};
    \node[draw,rectangle,fill=blue!15,minimum width=2cm, right=of mo] (mm) {\gls{mm-1qfa}};
    \node[draw,rectangle,fill=blue!15,minimum width=2cm, below=of mo] (lq) {\gls{lqfa}};
    \node[draw,rectangle,fill=blue!15,minimum width=2.8cm, right=of lq] (hybrid) {\gls{1qfac}/\gls{cl-1qfa}};
    \node[draw,rectangle,fill=blue!15,minimum width=2.5cm, below=of lq] (enhanced) {\gls{a-qfa}/\gls{mlqfa}};
    
    \draw[->,thick] (mo) -- (mm) node[midway,above] {\small +Measurements};
    \draw[->,thick] (mo) -- (lq) node[midway,left] {\small +Collapse Risk};
    \draw[->,thick] (lq) -- (hybrid) node[midway,above] {\small +Classical Control};
    \draw[->,thick] (hybrid) -- (enhanced) node[midway,right] {\small +Ancillas/Blocks};
\end{tikzpicture}
\caption{Hierarchy of one-way QFAs.}
\label{fig:one_way_hierarchy}
\end{figure}

%TODO: complete the table
\begin{table}[ht]
\centering
\label{tab:one_way}
\begin{tabular}{|l|c|c|c|}
\hline
\textbf{Model} & \textbf{Language Class} & \textbf{State Complexity} & \textbf{Key Limitation} \\ \hline
MO-1QFA   & Reversible Regular & $O(\log n)$ & Non-closed under union \\ \hline
MM-1QFA   & Regular (bounded error) & $O(\log n)$ & Measurement overhead \\ \hline
1QFAC     & Regular & $O(1)$ (quantum) & Undecidable equivalence \\ \hline
MLQFA     & Context-sensitive & $O(2^k)$ & Exponential in $k$ \\ \hline
\end{tabular}
\caption{Comparison of One-Way QFA Models}
\end{table}

\subsubsection{Key Findings}
Hybrid models (1QFAC/CL-1QFA) provide an optimal balance between quantum efficiency and classical reliability. Although MLQFA extend language recognition capabilities, their exponential state growth limits practical applicability.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection*{\glsentrylongpl{1.5qfa}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Summary}
The \gls{1.5qfa} extends the one-way paradigm by permitting a limited lookback through a fixed-size sliding window. Key points include:
\begin{itemize}
    \item Processes nested languages (e.g., $\{ww^Rw\}$) in linear time.
    \item Outperforms pure one-way models in recognition power.
    \item Restricted by the fixed window size $k$, which limits handling of unbounded context.
\end{itemize}

%TODO: not clear which language classes are recognized
\subsubsection{Schematic Diagram}
\begin{figure}[ht]
\centering
\begin{tikzpicture}
    \draw[->] (0,0) -- (5,0) node[right] {Input Tape};
    \foreach \x in {0.5,1.5,...,4.5} 
        \draw[fill=gray!20] (\x,0.2) rectangle (\x+1,0.7);
    \draw[red,->] (2.5,-0.5) -- (2.5,0) node[above] {Sliding Window};
\end{tikzpicture}
\caption{1.5-way QFA operation with a sliding window mechanism.}
\label{fig:1.5qfa}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection*{\glsentrylongpl{2qfa}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Summary}
Two-way QFAs enable full bidirectional tape access, which allows them to recognize more complex (non-regular) languages:
\begin{itemize}
    \item \textbf{2QFA}: A pure quantum two-way model capable of recognizing languages such as $\{a^nb^n\}$.
    \item \textbf{2QCFA/kTQCFA}: Hybrid variants incorporating classical control, often achieving recognition (e.g., palindromes or $k$-tape dependencies) with reduced quantum memory.
\end{itemize}

%TODO: useless figure
\subsubsection{Comparative Insights}
\begin{figure}[ht]
\centering
\begin{tikzpicture}[node distance=2cm]
    \node[draw,circle,fill=red!20] (q1) {$q_1$};
    \node[draw,circle,fill=red!20,right=of q1] (q2) {$q_2$};
    \draw[<->,thick] (q1) -- node[midway, above] {Left/Right Moves} (q2);
\end{tikzpicture}
\caption{Bidirectional transitions in Two-Way QFAs.}
\label{fig:two_way}
\end{figure}

\begin{table}[ht]
\centering
\caption{Two-Way QFA Comparison}
\label{tab:two_way}
\begin{tabular}{|l|c|c|}
\hline
\textbf{Model} & \textbf{Quantum States} & \textbf{Expressiveness} \\ \hline
2QFA  & Linear in input & Non-regular languages \\ \hline
2QCFA & Constant & Context-sensitive languages \\ \hline
kTQCFA & $O(k)$ & $k$-tape dependencies \\ \hline
\end{tabular}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection*{Hybrid Classical-Quantum Models}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Summary}
Hybrid models integrate classical logic with quantum processing:
\begin{itemize}
    \item \textbf{SQA}: Combines classical steering with quantum evolution.
    \item \textbf{QCPA}: Utilizes parity-based switching between classical and quantum modes.
    \item \textbf{BCQFA}: Employs blind counters to process balanced languages.
\end{itemize}

%TODO: useless figure
\begin{figure}[ht]
\centering
\begin{tikzpicture}[node distance=2cm]
    \node[draw,rectangle,fill=green!20] (classical) {Classical Control};
    \node[draw,rectangle,fill=blue!20,right=of classical] (quantum) {Quantum Register};
    \draw[<->,thick] (classical) -- node[above] {Synchronization} (quantum);
\end{tikzpicture}
\caption{Architecture of a hybrid classical-quantum model.}
\label{fig:hybrid}
\end{figure}

%TODO: be more specific
\subsubsection{Comparative Insights}
Hybrid models provide a favorable balance of classical robustness and quantum speedup, making them among the most promising for practical implementations.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection*{Generalised Models}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Summary}
Generalised \glspl{qfa} extend the conventional unitary framework by incorporating non-unitary evolution:
\begin{itemize}
    \item \textbf{gQFA}: Uses \gls{cptp} maps to model noise \cite{gruska2005}.
    \item \textbf{MO-1GQFA/MM-1GQFA}: Generalised versions of one-way QFAs with enhanced robustness.
    \item \textbf{OTQFA}: Incorporates Lindbladian dynamics to explicitly handle decoherence.
\end{itemize}

\begin{table}[ht]
\centering
\label{tab:general}
\begin{tabular}{|l|c|c|}
\hline
\textbf{Model} & \textbf{Decoherence Handling} & \textbf{Complexity} \\ \hline
gQFA   & CPTP maps (Markovian noise) & Quadratic slowdown \\ \hline
OTQFA & Lindbladian operators & PSPACE-level \\ \hline
\end{tabular}
\caption{Generalised QFA Characteristics}
\end{table}

\subsubsection{Comparative Insights}
While generalised models are crucial for addressing realistic noise, their increased complexity limits near-term practical deployment relative to simpler hybrid models.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection*{Specialized Models}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Summary}
Specialized QFAs incorporate additional memory structures to extend their computational power:
\begin{itemize}
    \item \textbf{QQA/QPA}: Utilize quantum queues or stacks to recognize context-sensitive or EXPTIME languages.
    \item \textbf{PSQFA}: Leverage postselection to amplify correct outcomes under idealized conditions.
\end{itemize}

\subsubsection{Comparison}
\begin{figure}[ht]
\centering
\begin{tikzpicture}
    \node[draw,cylinder,fill=yellow!20,shape aspect=3] (queue) at (0,0) {Quantum Queue};
    \node[draw,rectangle,fill=blue!20,right=of queue] (control) {Control Unit};
    \draw[->] (control) -- (queue) node[midway,above] {Enqueue/Dequeue};
\end{tikzpicture}
\caption{Architecture of a quantum queue automaton.}
\label{fig:qqa}
\end{figure}

\subsubsection{Comparative Insights}
Although specialized models can recognize language classes beyond regular and context-free, their increased state complexity and error management issues make them less attractive for practical implementations.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection*{Promise Problem Solvers}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Summary}
Promise problem solvers are tailored for inputs that meet specific conditions:
\begin{itemize}
    \item \textbf{Exact-QFA}: Achieves zero-error recognition for promise problems (e.g., EVENODD$_k$), but its applicability is limited.
    \item \textbf{BEQFA}: Allows bounded error recognition, broadening the range of recognizable languages while tolerating implementation inaccuracies.
\end{itemize}

\subsubsection{Comparison}
\begin{table}[ht]
\centering
\label{tab:promise}
\begin{tabular}{|l|c|c|c|}
\hline
\textbf{Model} & \textbf{Error Guarantee} & \textbf{Applicability} & \textbf{Complexity} \\ \hline
Exact-QFA & Zero error (for promises) & Narrow domain & Moderate \\ \hline
BEQFA    & Bounded error & Broader classes & Low to moderate \\ \hline
\end{tabular}
\caption{Promise Problem Solvers: Characteristics}
\end{table}

\subsubsection{Comparative Insights}
Promise problem solvers deliver high reliability under specific input conditions but are less flexible in general-purpose language recognition.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection*{Interactive Models}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Summary}
Interactive models extend QFA capabilities via communication protocols between a prover and a verifier:
\begin{itemize}
    \item \textbf{QIP(1QFA)}: Single-prover interactive systems for regular languages, operating with $O(\log n)$ qubits \cite{yakaryilmaz2013verification}.
    \item \textbf{QMIP(2QCFA)}: Multi-prover systems utilizing entanglement to recognize even recursively enumerable languages, albeit with high resource demands.
\end{itemize}

\subsubsection{Comparison}
\begin{figure}[ht]
\centering
\begin{tikzpicture}[node distance=2cm, auto]
    \node[draw, ellipse, fill=purple!10] (Prover) {Prover};
    \node[draw, ellipse, fill=purple!10, right=of Prover, node distance=4cm] (Verifier) {Verifier (QFA)};
    \draw[<->, thick] (Prover) -- node[midway, above] {Interaction} (Verifier);
\end{tikzpicture}
\caption{Interactive protocol between prover and verifier in QIP systems.}
\label{fig:interactive}
\end{figure}

\begin{table}[ht]
\centering
\label{tab:interactive}
\begin{tabular}{|l|c|c|}
\hline
\textbf{Model} & \textbf{Provers} & \textbf{Practicality} \\ \hline
QIP(1QFA) & 1 & Moderate \\ \hline
QMIP(2QCFA) & Multiple & Experimental \\ \hline
\end{tabular}
\caption{Interactive Model Comparison}
\end{table}

\subsubsection{Comparative Insights}
Interactive models offer significant theoretical power and bridge automata with complexity theory. However, their high resource and network demands currently hinder practical deployment.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection*{Abstract and Algebraic Models}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Summary}
Abstract models provide a high-level, algebraic perspective on QFA:
\begin{itemize}
    \item \textbf{abstract-QFA}: A unified algebraic framework expressing \gls{bqp} languages, primarily theoretical \cite{manin1980computable}.
    \item \textbf{OLVA}: Models quantum logic using orthomodular lattices for niche applications.
    \item \textbf{MPSQFA}: Uses tensor network (matrix product state) methods to simulate quantum state evolution \cite{vidal2003efficient}.
\end{itemize}

\subsubsection{Comparison}
\begin{table}[ht]
\centering
\label{tab:abstract}
\begin{tabular}{|l|c|c|c|}
\hline
\textbf{Model} & \textbf{Theoretical Focus} & \textbf{Applicability} & \textbf{Complexity} \\ \hline
abstract-QFA & Algebraic formulation & Unification of QFA theory & High \\ \hline
OLVA        & Quantum logic framework & Niche applications & Very high \\ \hline
MPSQFA      & Tensor network simulation & Theoretical exploration & High \\ \hline
\end{tabular}
\caption{Abstract Models: Characteristics}
\end{table}

\subsubsection{Comparative Insights}
Abstract models are essential for advancing a unified theoretical foundation of quantum automata. Their high complexity and abstract nature, however, limit their immediate practical application.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Overall Comparative Discussion and Final Evaluation}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
This chapter has presented a detailed comparative analysis of QFA models across nine categories. Key findings include:
\begin{itemize}
    \item \textbf{One-Way Models} are resource-efficient but limited in expressiveness.
    \item \textbf{1.5-Way and Two-Way Models} enhance recognition capabilities at the expense of increased complexity.
    \item \textbf{Hybrid Models} (e.g., 1QFAC/CL-1QFA) offer the best balance for practical applications.
    \item \textbf{Generalised Models} effectively handle realistic noise, though with higher complexity (e.g., Gruska's noise models \cite{gruska2005}).
    \item \textbf{Specialized Models} extend language recognition capabilities but are hampered by high state complexity and error management challenges.
    \item \textbf{Promise Problem Solvers} provide high reliability under strict input conditions, yet their applicability is narrow.
    \item \textbf{Interactive Models} push computational boundaries but require substantial resources.
    \item \textbf{Abstract and Algebraic Models} are crucial for theoretical unification, yet are currently less practical.
\end{itemize}
Overall, hybrid and generalised models emerge as the most promising for near-term quantum computing applications, while promise problem solvers, specialized, interactive, and abstract models continue to provide valuable insights for advancing the theoretical foundations of quantum automata.

\subsubsection{Key Models and Promising Directions}
\begin{itemize}
    \item \textbf{Most Expressive:} \gls{qmip2qcfa} and \gls{abstract-qfa} demonstrate extraordinary theoretical power but are experimentally challenging.
    \item \textbf{Most Practical:} \gls{mm-1qfa} and hybrid models like \gls{1qfac} offer a good balance between error control and state complexity.
    \item \textbf{Balanced Design:} \gls{2qcfa}, with constant quantum memory and polynomial time operation, represent a promising middle ground.
\end{itemize}

\subsubsection{Final Evaluation}
In summary, while theoretical models such as interactive and abstract QFAs push the boundaries of what quantum automata can achieve, hybrid and generalised models offer the most viable path toward practical quantum advantage in language recognition. Future research should focus on:
\begin{itemize}
    \item Developing robust error correction and state minimization techniques for hybrid architectures.
    \item Implementing hardware prototypes for 1.5-way and two-way models.
    \item Advancing algebraic frameworks to unify generalized and abstract models.
\end{itemize}

